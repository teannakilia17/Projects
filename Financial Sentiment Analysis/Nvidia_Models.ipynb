{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60a6192",
   "metadata": {},
   "source": [
    "# NVIDIA Earnings Transcript Scraper (Q1–Q4 FY2025)\n",
    "\n",
    "This notebook scrapes earnings call transcripts for NVIDIA (Q1–Q4 FY2025) from Fool.com, cleans the raw text to remove disclaimers and noise, and saves each cleaned transcript to a separate file.\n",
    "\n",
    "**Steps Covered:**\n",
    "1. Scrape earnings call transcripts using Selenium\n",
    "2. Clean the scraped text\n",
    "3. Save a single cleaned `.txt` file for each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dba760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time  \n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d545ba5",
   "metadata": {},
   "source": [
    "# Step 1: Scrape Transcript from Fool.com\n",
    "\n",
    "This function uses Selenium to open the transcript webpage, accept cookies, and extract all paragraph text from the main article body.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38c78b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scraping function\n",
    "def scrape_clean_transcript(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Accept cookie banner if present\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html/body/div[13]/div[2]/div/div/div[2]/div/div/button[2]').click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Extract earning call content\n",
    "    try:\n",
    "        article_body = driver.find_element(By.XPATH, \"/html/body/div[9]/div[3]/div[2]/section[2]/div/div[2]/div[1]/div[1]\")\n",
    "        paragraphs = article_body.find_elements(By.XPATH, \"//p\")\n",
    "        raw_text = \"\\n\".join([p.text for p in paragraphs if p.text.strip()])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting transcript from {url}: {e}\")\n",
    "        raw_text = \"\"\n",
    "\n",
    "    driver.quit()\n",
    "    return raw_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f4843",
   "metadata": {},
   "source": [
    "# Step 2: Clean the Transcript Text\n",
    "\n",
    "This function removes empty lines and disclaimer/legal language. It also collapses multiple line breaks into a single one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c978fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcript(text):\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "\n",
    "    # Remove  \"header\" lines \n",
    "    cleaned_lines = []\n",
    "    for line in lines:\n",
    "        if (\n",
    "            any(kw in line.lower() for kw in [\"image source\", \"nvidia\", \"earnings call\", \"et\"]) and\n",
    "            len(cleaned_lines) < 5\n",
    "        ):\n",
    "            continue\n",
    "        cleaned_lines.append(line.strip())\n",
    "\n",
    "    text = \"\\n\".join(cleaned_lines).strip()\n",
    "\n",
    "    # Truncate footer section\n",
    "    footer_start = text.find(\"More NVDA analysis\")\n",
    "    if footer_start != -1:\n",
    "        text = text[:footer_start].strip()\n",
    "\n",
    "    # Clean up legal terms & short lines\n",
    "    final_lines = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        if len(line.strip()) < 5:\n",
    "            continue\n",
    "        if any(term in line.lower() for term in [\"forward-looking\", \"safe harbor\", \"disclaimer\"]):\n",
    "            continue\n",
    "        final_lines.append(line.strip())\n",
    "\n",
    "    cleaned_text = \"\\n\".join(final_lines)\n",
    "    return re.sub(r'\\n+', '\\n', cleaned_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3288c",
   "metadata": {},
   "source": [
    "# Step 3: Save Cleaned Transcript to File\n",
    "\n",
    "This function saves the cleaned transcript to a `.txt` file inside the `clean_transcripts/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "715bed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clean trasncripts as txt files\n",
    "def save_transcript(text, filename):\n",
    "    os.makedirs(\"clean_transcripts\", exist_ok=True)\n",
    "    path = os.path.join(\"clean_transcripts\", filename)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa579632",
   "metadata": {},
   "source": [
    "# Step 4: Process All Four Quarters (Q1–Q4 FY2025)\n",
    "\n",
    "We define a dictionary of transcript URLs and filenames. The script loops through them, scrapes the data, cleans it, and saves the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4e7429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing NVDA_q1_2025.txt ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, url \u001b[38;5;129;01min\u001b[39;00m transcripts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     raw \u001b[38;5;241m=\u001b[39m scrape_clean_transcript(url)\n\u001b[1;32m     12\u001b[0m     clean \u001b[38;5;241m=\u001b[39m clean_transcript(raw)\n\u001b[1;32m     13\u001b[0m     save_transcript(clean, filename)\n",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m, in \u001b[0;36mscrape_clean_transcript\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_clean_transcript\u001b[39m(url):\n\u001b[0;32m----> 3\u001b[0m     driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mService(ChromeDriverManager()\u001b[38;5;241m.\u001b[39minstall()))\n\u001b[1;32m      4\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m      5\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/webdriver_manager/chrome.py:40\u001b[0m, in \u001b[0;36mChromeDriverManager.install\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minstall\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     driver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_driver_binary_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver)\n\u001b[1;32m     41\u001b[0m     os\u001b[38;5;241m.\u001b[39mchmod(driver_path, \u001b[38;5;241m0o755\u001b[39m)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m driver_path\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/webdriver_manager/core/manager.py:40\u001b[0m, in \u001b[0;36mDriverManager._get_driver_binary_path\u001b[0;34m(self, driver)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_path\n\u001b[1;32m     39\u001b[0m os_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_os_type()\n\u001b[0;32m---> 40\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_manager\u001b[38;5;241m.\u001b[39mdownload_file(driver\u001b[38;5;241m.\u001b[39mget_driver_download_url(os_type))\n\u001b[1;32m     41\u001b[0m binary_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_manager\u001b[38;5;241m.\u001b[39msave_file_to_cache(driver, file)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m binary_path\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/webdriver_manager/core/download_manager.py:32\u001b[0m, in \u001b[0;36mWDMDownloadManager.download_file\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m     30\u001b[0m log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDriver downloading response is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_filename_from_url(url)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m File(response, file_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/webdriver_manager/core/file_manager.py:12\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, stream, file_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream, file_name):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__stream \u001b[38;5;241m=\u001b[39m stream\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_name \u001b[38;5;241m=\u001b[39m file_name\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(amt\u001b[38;5;241m=\u001b[39mamt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_read(amt)\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt, read1\u001b[38;5;241m=\u001b[39mread1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/http/client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transcripts = {\n",
    "    \"NVDA_q1_2025.txt\": \"https://www.fool.com/earnings/call-transcripts/2024/05/29/nvidia-nvda-q1-2025-earnings-call-transcript/\",\n",
    "    \"NVDA_q2_2025.txt\": \"https://www.fool.com/earnings/call-transcripts/2024/08/28/nvidia-nvda-q2-2025-earnings-call-transcript/\",\n",
    "    \"NVDA_q3_2025.txt\": \"https://www.fool.com/earnings/call-transcripts/2024/11/20/nvidia-nvda-q3-2025-earnings-call-transcript/\",\n",
    "    \"NVDA_q4_2025.txt\": \"https://www.fool.com/earnings/call-transcripts/2025/02/26/nvidia-nvda-q4-2025-earnings-call-transcript/\"\n",
    "}\n",
    "\n",
    "# Process each transcript URL\n",
    "for filename, url in transcripts.items():\n",
    "    print(f\"\\nProcessing {filename} ...\")\n",
    "    raw = scrape_clean_transcript(url)\n",
    "    clean = clean_transcript(raw)\n",
    "    save_transcript(clean, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4e2a8",
   "metadata": {},
   "source": [
    "# Step 5: Preprocess the Cleaned Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca012aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 103 speaker blocks to clean_transcripts/NVIDIA_all_quarters_speaker_blocks.csv\n",
      "Saved 103 speaker blocks to clean_transcripts/NVIDIA_all_quarters_speaker_blocks.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/lxfmpgzx1d9dfh29gsnfn3yh0000gn/T/ipykernel_11179/2637116945.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['speaker'].ffill(inplace=True)\n",
      "/var/folders/g0/lxfmpgzx1d9dfh29gsnfn3yh0000gn/T/ipykernel_11179/2637116945.py:68: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['title'].ffill(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define the input transcript files and associated quarters\n",
    "transcript_files = {\n",
    "    'Q1_2025': 'clean_transcripts/NVDA_q1_2025.txt',\n",
    "    'Q2_2025': 'clean_transcripts/NVDA_q2_2025.txt',\n",
    "    'Q3_2025': 'clean_transcripts/NVDA_q3_2025.txt',\n",
    "    'Q4_2025': 'clean_transcripts/NVDA_q4_2025.txt',\n",
    "}\n",
    "\n",
    "records = []\n",
    "\n",
    "# Improved regex pattern for speaker lines\n",
    "speaker_pattern = re.compile(\n",
    "    r'^(?P<speaker>([A-Z][a-zA-Z.,\\'-]+\\s){1,3}[A-Z][a-zA-Z.,\\'-]+)\\s--\\s(?P<title>[A-Za-z][^:\\n]+)$'\n",
    ")\n",
    "\n",
    "for quarter, path in transcript_files.items():\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        current_speaker = None\n",
    "        current_title = None\n",
    "        buffer = []\n",
    "\n",
    "        for raw_line in f:\n",
    "            line = raw_line.strip()\n",
    "\n",
    "            # Remove notes like [Operator Instructions]\n",
    "            line = re.sub(r'\\[.*?\\]', '', line).strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            match = speaker_pattern.match(line)\n",
    "            if match:\n",
    "                # Save previous speaker block\n",
    "                if current_speaker and buffer:\n",
    "                    content = ' '.join(buffer).strip()\n",
    "                    if len(content) > 30:\n",
    "                        records.append({\n",
    "                            'quarter': quarter,\n",
    "                            'speaker': current_speaker,\n",
    "                            'title': current_title,\n",
    "                            'content': content\n",
    "                        })\n",
    "\n",
    "                # Start new block\n",
    "                current_speaker = match.group('speaker').strip()\n",
    "                current_title = match.group('title').strip()\n",
    "                buffer = []\n",
    "\n",
    "            else:\n",
    "                # If line is misparsed (e.g. a regular sentence starting with \"And I...\"), add to buffer\n",
    "                buffer.append(line)\n",
    "\n",
    "        # If there is content in buffer with current speaker > 30 characters then add to final record\n",
    "        if current_speaker and buffer:\n",
    "            content = ' '.join(buffer).strip()\n",
    "            if len(content) > 30:\n",
    "                records.append({\n",
    "                    'quarter': quarter,\n",
    "                    'speaker': current_speaker,\n",
    "                    'title': current_title,\n",
    "                    'content': content\n",
    "                })\n",
    "\n",
    "# Save to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Forward-fill missing speakers and titles\n",
    "df['speaker'].ffill(inplace=True)\n",
    "df['title'].ffill(inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'clean_transcripts/NVIDIA_all_quarters_speaker_blocks.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved {len(df)} speaker blocks to {output_path}\")\n",
    "\n",
    "df['speaker'].ffill(inplace=True)\n",
    "if 'title' in df.columns:\n",
    "    df['title'].ffill(inplace=True)\n",
    "\n",
    "# Save cleaned speaker blocks\n",
    "output_path = 'clean_transcripts/NVIDIA_all_quarters_speaker_blocks.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df)} speaker blocks to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bab691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Simona Jankowski</td>\n",
       "      <td>Vice President, Investor Relations</td>\n",
       "      <td>They just revealed what they believe are the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Colette Kress</td>\n",
       "      <td>Executive Vice President, Chief Financial Officer</td>\n",
       "      <td>Thanks, Simona. Q1 was another record quarter....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Jensen Huang</td>\n",
       "      <td>President and Chief Operating Officer</td>\n",
       "      <td>Thanks, Colette. The industry is going through...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Simona Jankowski</td>\n",
       "      <td>Vice President, Investor Relations</td>\n",
       "      <td>Thank you, Jensen. We will now open the call f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Stacy Rasgon</td>\n",
       "      <td>AllianceBernstein -- Analyst</td>\n",
       "      <td>Hi, guys. Thanks for taking my questions. My f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter           speaker  \\\n",
       "0  Q1_2025  Simona Jankowski   \n",
       "1  Q1_2025     Colette Kress   \n",
       "2  Q1_2025      Jensen Huang   \n",
       "3  Q1_2025  Simona Jankowski   \n",
       "4  Q1_2025      Stacy Rasgon   \n",
       "\n",
       "                                               title  \\\n",
       "0                 Vice President, Investor Relations   \n",
       "1  Executive Vice President, Chief Financial Officer   \n",
       "2              President and Chief Operating Officer   \n",
       "3                 Vice President, Investor Relations   \n",
       "4                       AllianceBernstein -- Analyst   \n",
       "\n",
       "                                             content  \n",
       "0  They just revealed what they believe are the 1...  \n",
       "1  Thanks, Simona. Q1 was another record quarter....  \n",
       "2  Thanks, Colette. The industry is going through...  \n",
       "3  Thank you, Jensen. We will now open the call f...  \n",
       "4  Hi, guys. Thanks for taking my questions. My f...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the uploaded CSV file containing all quarters' speaker blocks\n",
    "df_speaker_blocks = pd.read_csv(\"clean_transcripts/NVIDIA_all_quarters_speaker_blocks.csv\")\n",
    "\n",
    "# Display the first few rows to confirm structure\n",
    "df_speaker_blocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de621b",
   "metadata": {},
   "source": [
    "# Step 6: Speaker-level Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd511452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load your speaker blocks file (all quarters)\n",
    "df = pd.read_csv(\"clean_transcripts/NVIDIA_all_quarters_speaker_blocks.csv\")\n",
    "\n",
    "# FinBERT model setup\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "finbert = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def get_sentiment_chunks(text, max_chunk_words=200):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return [(\"EMPTY\", 0.0)]\n",
    "\n",
    "    # Split text into words, then wrap into word chunks\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i + max_chunk_words]) for i in range(0, len(words), max_chunk_words)]\n",
    "\n",
    "    results = []\n",
    "    for chunk in chunks:\n",
    "        try:\n",
    "            result = finbert(chunk)[0]  # Let pipeline handle tokenization\n",
    "            results.append((result[\"label\"], result[\"score\"]))\n",
    "        except:\n",
    "            results.append((\"ERROR\", 0.0))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Apply FinBERT to each content (in chunks)\n",
    "df[\"sentiment_chunks\"] = df[\"content\"].apply(get_sentiment_chunks)\n",
    "\n",
    "# Aggregation function (majority vote + max score for top label)\n",
    "def aggregate_sentiment(chunk_list):\n",
    "    if not chunk_list or chunk_list == [(\"EMPTY\", 0.0)]:\n",
    "        return \"EMPTY\", 0.0\n",
    "\n",
    "    from collections import Counter\n",
    "    label_counts = Counter([label for label, _ in chunk_list])\n",
    "    top_label = label_counts.most_common(1)[0][0]\n",
    "    max_conf = max(score for label, score in chunk_list if label == top_label)\n",
    "    return top_label, max_conf\n",
    "\n",
    "# Apply aggregation\n",
    "df[[\"sentiment\", \"confidence\"]] = df[\"sentiment_chunks\"].apply(lambda x: pd.Series(aggregate_sentiment(x)))\n",
    "\n",
    "\n",
    "def map_five_categories(row):\n",
    "    label = row['sentiment'].lower()\n",
    "    score = row['confidence']\n",
    "\n",
    "    if label == 'positive':\n",
    "        return 'Strong Positive' if score > 0.85 else 'Slightly Positive'\n",
    "    elif label == 'negative':\n",
    "        return 'Strong Negative' if score > 0.85 else 'Sli Negative'\n",
    "    elif label == 'neutral':\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Uncertain'\n",
    "\n",
    "df['sentiment_category'] = df.apply(map_five_categories, axis=1)\n",
    "\n",
    "#  Re-order columns\n",
    "df = df[['quarter', 'speaker', 'title', 'content', 'sentiment', 'confidence', 'sentiment_category']]\n",
    "\n",
    "# Save output\n",
    "df.to_csv(\"clean_transcripts/NVIDIA_finbert_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50146026",
   "metadata": {},
   "source": [
    "# Step 7: using LLMs to get sentiment score for each block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c6b6d",
   "metadata": {},
   "source": [
    "## API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'sk-58c0df73519c42debe27d41e164d455a'\n",
    "base_url = \"https://api.deepseek.com\"\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f4a26",
   "metadata": {},
   "source": [
    "## Getting the sentiment score for each blocks of text using an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34897f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a payload of {id, text} objects\n",
    "payload = (\n",
    "    df[[\"content\"]]\n",
    "    .reset_index()                             # bring the DataFrame index into a column\n",
    "    .rename(columns={\"index\": \"id\", \"content\": \"text\"})\n",
    "    .to_dict(orient=\"records\")\n",
    ")\n",
    "\n",
    "# Craft your messages\n",
    "system_prompt = \"\"\"\n",
    "You are a sentiment-analysis engine.\n",
    "I will give you a JSON array of objects like:\n",
    "  [ { \"id\": 0, \"text\": \"…\"}, { \"id\": 1, \"text\": \"…\"}, … ]\n",
    "\n",
    "For each text, return a probability distribution over the five sentiment classes:\n",
    "Strong Negative, Slightly Negative, Neutral, Slightly Positive, Strong Positive.\n",
    "Label your columns:\n",
    "\n",
    "id,\n",
    "LLM_sentiment, \n",
    "LLM_pct_strong_positive,\n",
    "LLM_pct_slightly_positive,\n",
    "LLM_pct_neutral,\n",
    "LLM_pct_slightly_negative,\n",
    "LLM_pct_strong_negative\n",
    "\n",
    "—with each LLM_pct_* a float from 0.0–1.0 summing to 1.0, one row per paragraph,\n",
    "no markdown fences or commentary, pure CSV.\n",
    "-for sentiment, choose one of the five classes. \n",
    "\"\"\"\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": json.dumps(payload, indent=2)}\n",
    "    ],\n",
    "    temperature=0.0,\n",
    "    top_p=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f68c1f",
   "metadata": {},
   "source": [
    "## Merging with the original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>sentiment_category</th>\n",
       "      <th>role_category</th>\n",
       "      <th>LLM_sentiment</th>\n",
       "      <th>LLM_pct_strong_positive</th>\n",
       "      <th>LLM_pct_slightly_positive</th>\n",
       "      <th>LLM_pct_neutral</th>\n",
       "      <th>LLM_pct_slightly_negative</th>\n",
       "      <th>LLM_pct_strong_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Simona Jankowski</td>\n",
       "      <td>Vice President, Investor Relations</td>\n",
       "      <td>They just revealed what they believe are the 1...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.949520</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Other</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Colette Kress</td>\n",
       "      <td>Executive Vice President, Chief Financial Officer</td>\n",
       "      <td>Thanks, Simona. Q1 was another record quarter....</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.952649</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>CFO</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Jensen Huang</td>\n",
       "      <td>President and Chief Operating Officer</td>\n",
       "      <td>Thanks, Colette. The industry is going through...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.758598</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Other</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Simona Jankowski</td>\n",
       "      <td>Vice President, Investor Relations</td>\n",
       "      <td>Thank you, Jensen. We will now open the call f...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.931907</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Other</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1_2025</td>\n",
       "      <td>Stacy Rasgon</td>\n",
       "      <td>AllianceBernstein -- Analyst</td>\n",
       "      <td>Hi, guys. Thanks for taking my questions. My f...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.893501</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Q4_2025</td>\n",
       "      <td>Jensen Huang</td>\n",
       "      <td>President and Chief Executive Officer</td>\n",
       "      <td>Yeah. I appreciate it. First of all, people ar...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.899786</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Q4_2025</td>\n",
       "      <td>Atif Malik</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Hi. Thank you for taking my question. I have a...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.807783</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Q4_2025</td>\n",
       "      <td>Colette M. Kress</td>\n",
       "      <td>Chief Financial Officer, Executive Vice President</td>\n",
       "      <td>Yeah. Thanks for the question. Our gross margi...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>CFO</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Q4_2025</td>\n",
       "      <td>Colette M. Kress</td>\n",
       "      <td>Chief Financial Officer, Executive Vice President</td>\n",
       "      <td>We are going to open up to Jensen. A couple of...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855628</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>CFO</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Q4_2025</td>\n",
       "      <td>Jensen Huang</td>\n",
       "      <td>President and Chief Executive Officer</td>\n",
       "      <td>I just wanted to thank you. Thank you, Colette...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.945948</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     quarter           speaker  \\\n",
       "0    Q1_2025  Simona Jankowski   \n",
       "1    Q1_2025     Colette Kress   \n",
       "2    Q1_2025      Jensen Huang   \n",
       "3    Q1_2025  Simona Jankowski   \n",
       "4    Q1_2025      Stacy Rasgon   \n",
       "..       ...               ...   \n",
       "98   Q4_2025      Jensen Huang   \n",
       "99   Q4_2025        Atif Malik   \n",
       "100  Q4_2025  Colette M. Kress   \n",
       "101  Q4_2025  Colette M. Kress   \n",
       "102  Q4_2025      Jensen Huang   \n",
       "\n",
       "                                                 title  \\\n",
       "0                   Vice President, Investor Relations   \n",
       "1    Executive Vice President, Chief Financial Officer   \n",
       "2                President and Chief Operating Officer   \n",
       "3                   Vice President, Investor Relations   \n",
       "4                         AllianceBernstein -- Analyst   \n",
       "..                                                 ...   \n",
       "98               President and Chief Executive Officer   \n",
       "99                                             Analyst   \n",
       "100  Chief Financial Officer, Executive Vice President   \n",
       "101  Chief Financial Officer, Executive Vice President   \n",
       "102              President and Chief Executive Officer   \n",
       "\n",
       "                                               content sentiment  confidence  \\\n",
       "0    They just revealed what they believe are the 1...   neutral    0.949520   \n",
       "1    Thanks, Simona. Q1 was another record quarter....  positive    0.952649   \n",
       "2    Thanks, Colette. The industry is going through...   neutral    0.758598   \n",
       "3    Thank you, Jensen. We will now open the call f...   neutral    0.931907   \n",
       "4    Hi, guys. Thanks for taking my questions. My f...   neutral    0.893501   \n",
       "..                                                 ...       ...         ...   \n",
       "98   Yeah. I appreciate it. First of all, people ar...   neutral    0.899786   \n",
       "99   Hi. Thank you for taking my question. I have a...   neutral    0.807783   \n",
       "100  Yeah. Thanks for the question. Our gross margi...   neutral    0.770526   \n",
       "101  We are going to open up to Jensen. A couple of...   neutral    0.855628   \n",
       "102  I just wanted to thank you. Thank you, Colette...   neutral    0.945948   \n",
       "\n",
       "    sentiment_category role_category    LLM_sentiment  \\\n",
       "0              Neutral         Other          Neutral   \n",
       "1      Strong Positive           CFO  Strong Positive   \n",
       "2              Neutral         Other  Strong Positive   \n",
       "3              Neutral         Other          Neutral   \n",
       "4              Neutral       Analyst          Neutral   \n",
       "..                 ...           ...              ...   \n",
       "98             Neutral           CEO          Neutral   \n",
       "99             Neutral       Analyst          Neutral   \n",
       "100            Neutral           CFO          Neutral   \n",
       "101            Neutral           CFO          Neutral   \n",
       "102            Neutral           CEO  Strong Positive   \n",
       "\n",
       "     LLM_pct_strong_positive  LLM_pct_slightly_positive  LLM_pct_neutral  \\\n",
       "0                        0.1                       0.20             0.60   \n",
       "1                        0.7                       0.20             0.10   \n",
       "2                        0.8                       0.15             0.05   \n",
       "3                        0.0                       0.10             0.80   \n",
       "4                        0.1                       0.20             0.60   \n",
       "..                       ...                        ...              ...   \n",
       "98                       0.1                       0.20             0.60   \n",
       "99                       0.1                       0.20             0.60   \n",
       "100                      0.1                       0.20             0.60   \n",
       "101                      0.1                       0.20             0.60   \n",
       "102                      0.7                       0.20             0.10   \n",
       "\n",
       "     LLM_pct_slightly_negative  LLM_pct_strong_negative  \n",
       "0                          0.1                      0.0  \n",
       "1                          0.0                      0.0  \n",
       "2                          0.0                      0.0  \n",
       "3                          0.1                      0.0  \n",
       "4                          0.1                      0.0  \n",
       "..                         ...                      ...  \n",
       "98                         0.1                      0.0  \n",
       "99                         0.1                      0.0  \n",
       "100                        0.1                      0.0  \n",
       "101                        0.1                      0.0  \n",
       "102                        0.0                      0.0  \n",
       "\n",
       "[103 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = resp.choices[0].message\n",
    "csv_str = msg.content\n",
    "# Convert CSV string to DataFrame\n",
    "sent_df = pd.read_csv(io.StringIO(csv_str))\n",
    "df = df.reset_index(drop=False).rename(columns={'index':'id'})\n",
    "df_with_sentiment = df.merge(\n",
    "    sent_df,            # contains id, sentiment, pct_*\n",
    "    on='id',            # join key\n",
    "    how='left'          # keep every original row\n",
    ")\n",
    "\n",
    "df_with_sentiment.drop(columns=['id'], inplace=True)  # drop the id column\n",
    "\n",
    "df_with_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "943ef996",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_with_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#save df_with_sentiment to csv\u001b[39;00m\n\u001b[1;32m      2\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_transcripts/NVIDIA_finbert_deepseek_output.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df_with_sentiment\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved sentiment output to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_with_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "#save df_with_sentiment to csv\n",
    "output_path = 'clean_transcripts/NVIDIA_finbert_deepseek_output.csv'\n",
    "df_with_sentiment.to_csv(output_path, index=False)\n",
    "print(f\"Saved sentiment output to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_mf_junk_in_df(df, text_col=\"content\"):\n",
    "    df = df.copy()\n",
    "    df[text_col] = df[text_col].astype(str).map(_demojibake_fix)\n",
    "    mask_junk = df[text_col].str.contains(_MF_JUNK_RE, na=False)\n",
    "    df = df.loc[~mask_junk].copy()\n",
    "    df[text_col] = df[text_col].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    df = df[df[text_col].str.len() > 3].copy()\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# One-off cleanup of a saved file:\n",
    "path = \"clean_transcripts/NVIDIA_finbert_deepseek_output.csv\"  # change as needed\n",
    "df = pd.read_csv(path)\n",
    "df_clean = clean_mf_junk_in_df(df, text_col=\"content\")\n",
    "out_path = path.replace(\".csv\", \"_clean.csv\")\n",
    "df_clean.to_csv(out_path, index=False)\n",
    "print(f\"Removed {len(df)-len(df_clean)} junk rows. Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7fc4fc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NVIDIA_full.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m NVIDIA_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNVIDIA_full.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Select only the required columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m NVIDIA_final \u001b[38;5;241m=\u001b[39m NVIDIA_final[[\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mManual Annotation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m ]]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/digital_env/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NVIDIA_full.csv'"
     ]
    }
   ],
   "source": [
    "NVIDIA_final = pd.read_csv(\"NVIDIA_full.csv\")\n",
    "\n",
    "# Select only the required columns\n",
    "NVIDIA_final = NVIDIA_final[[\n",
    "    \"quarter\",\n",
    "    \"content\",\n",
    "    \"sentiment_category\",\n",
    "    \"role_category\",\n",
    "    \"LLM_sentiment\",\n",
    "    \"Manual Annotation\"\n",
    "]]\n",
    "\n",
    "# Rename columns\n",
    "NVIDIA_final = NVIDIA_final.rename(columns={\n",
    "    \"title\": \"role_category\",\n",
    "    \"sentiment_category\": \"FinBERT_sentiment\",\n",
    "    \"Manual Annotations\": \"manual_annotation\"\n",
    "})\n",
    "\n",
    "# Rearrange columns so role_category comes before FinBERT_sentiment\n",
    "NVIDIA_final = NVIDIA_final[[\n",
    "    \"quarter\",\n",
    "    \"content\",\n",
    "    \"role_category\",\n",
    "    \"FinBERT_sentiment\",\n",
    "    \"LLM_sentiment\",\n",
    "    \"manual_annotation\"\n",
    "]]\n",
    "\n",
    "# Check the updated dataframe\n",
    "print(NVIDIA_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digital_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
