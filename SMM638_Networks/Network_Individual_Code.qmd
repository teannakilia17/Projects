---
title: "SMM638 Final Term Project"
author: "Teanna Puthucheary"
date: last-modified
abstract: This report aims to assist Sonic, a leading music label, in gaining a deeper understanding of their user and genre networks, as well as the interactions between individuals and genres on the Deezer platform. By analysing clustering patterns and leveraging various network metrics, the study provides visualisations and actionable insights into the dynamics of these relationships. 
format: 
  html:
    code-fold: true
    code-tools: true 
    code-line-numbers: true
  pdf: default
  ipynb: default

---
Describe problem
1. Assess the similarity between Deezer music genres
2. Identify homogenous groups of Deezer music genres
3. Highlight how social ties among users influence the similarity between music genres

### Workbook Setup 

# Import Libraries
```{python}
import pandas as pd
import networkx as nx
import numpy as np
import json
import matplotlib.pyplot as plt
from networkx.algorithms import bipartite as bp
import community as community_louvain
from collections import defaultdict
from collections import Counter



```

# Load the Data

```{python}
url1 = 'https://raw.githubusercontent.com/simoneSantoni/net-analysis-smm638/refs/heads/master/data/deezer_clean_data/HR_edges.csv'

fr  = pd.read_csv(url1)
fr.head()

with open ('/Users/HR_genres.json', 'r') as f:
    pr_json = json.load(f)
pr_json["11542"]

```

# Visualise the Data
```{python}
fr_g = nx.from_pandas_edgelist(fr, source='node_1', target='node_2')
fr_g

pr = pd.json_normalize(pr_json).T
pr.rename({0: 'genres'}, axis=1, inplace=True)
pr.head()

pr1 = pr.explode('genres')
pr1.reset_index(inplace=True)
pr1.rename({'index': 'user_id'}, axis=1, inplace=True)
pr1.head()
```

# Create a bipartite graph (Network X)
```{python}
X = nx.Graph()

genre_nodes = set(pr1.genres)
user_nodes = set(pr1.user_id)

X.add_nodes_from(user_nodes, bipartite=0)
X.add_nodes_from(genre_nodes, bipartite=1)

for i in range(len(pr1)):
    X.add_edge(pr1["user_id"][i], pr1["genres"][i])
    
is_bip = nx.is_bipartite(X)
is_bip

print(X)
print(pr1)
```

# Project a Weighted Graph (Network Z)
```{python}
Z = bp.weighted_projected_graph(X,genre_nodes)
weight = nx.get_edge_attributes(Z, "weight")
print(Z)

```

# Calculate Top 5 Overlapped with Genres 
```{python}
similar_genres = defaultdict(list)

for u, v, data in Z.edges(data=True):
    weight = data['weight']
    similar_genres[u].append((v, weight))  
    similar_genres[v].append((u, weight))  


for genre in similar_genres:
    similar_genres[genre] = sorted(similar_genres[genre], key=lambda x: x[1], reverse=True)


for genre, pairs in similar_genres.items():
    print(f"Genre: {genre}")
    i = 0
    for similar, weight in pairs:
        print(f"  Overlapped with Genre: {similar}, Weight: {weight}")
        if(i>5):
            break
        i+=1

```

# Network Analysis on Network Z
```{python}
# Network Analysis on network Z

# Degree Centrality: Identify highly connected nodes (hubs) in the network.
degree_centrality = nx.degree_centrality(Z)
print(sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]) # Top 10 nodes

# Betweenness Centrality: Find nodes or edges that act as bridges between communities.
betweenness = nx.betweenness_centrality(Z)
print(sorted(betweenness.items(), key=lambda x: x[1], reverse=True)[:10])

# Edge analysis - Examine high-weight edges to understand strong connections in your graph:
top_edges = sorted(Z.edges(data=True), key=lambda x: x[2]["weight"], reverse=True)
print(top_edges[:10])
```

# Calculate the % of Listeners Overlap for Most Commonly listened to together genres
```{python}
# Compute total listeners for each genre
genre_listeners = {node: Z.degree(node, weight="weight") for node in Z.nodes()}

# Analyze top edges
top_edges = sorted(Z.edges(data=True), key=lambda x: x[2]["weight"], reverse=True)

# Calculate percentage overlap for the top edges
overlap_results = []
for u, v, data in top_edges[:10]:  # Adjust the range as needed
    shared_listeners = data["weight"]
    total_u = genre_listeners[u]
    total_v = genre_listeners[v]
    
    # Calculate percentage overlap (use min-based or symmetric formula)
    percentage_overlap = (shared_listeners / min(total_u, total_v)) * 100
    # Optional: Use symmetric overlap
    # percentage_overlap = (shared_listeners / (total_u + total_v - shared_listeners)) * 100
    
    overlap_results.append((u, v, percentage_overlap))

# Display the results
print("Top Edges with Percentage Overlap:")
for u, v, overlap in overlap_results:
    print(f"Genres: {u} - {v}, Percentage Overlap: {overlap:.2f}%")
```


# Visualisng the Top 20 Most Listened to together Genres 
```{python}

# Convert edges to DataFrame
data = top_edges[:20]
df = pd.DataFrame(data, columns=['Genre 1', 'Genre 2', 'Weight'])
df['Weight'] = df['Weight'].apply(lambda x: x['weight'] if isinstance(x, dict) else x)
df['Weight'] = pd.to_numeric(df['Weight'])

# Create a graph from the DataFrame
G = nx.Graph()
for _, row in df.iterrows():
    G.add_edge(row['Genre 1'], row['Genre 2'], weight=row['Weight'])

# Draw the graph
pos = nx.spring_layout(G, seed=42, k=1)  # Positions for nodes
plt.figure(figsize=(6, 4))
nx.draw(
    G, pos,
    with_labels=True,
    node_size=500,
    node_color="skyblue",
    font_size=10,
    edge_color=[G[u][v]['weight'] for u, v in G.edges()],
    edge_cmap=plt.cm.Blues,
    width=2
)
plt.title("Top 20 Most Popular Genres In Common ")
plt.show()
```

# Using Louvain Communities to segregate Network Z into categories

```{python}
## Louvain Communities
fit = nx.community.louvain_communities(Z, weight="weight")
print(len(fit))  #Number of different communities

communities = tuple(sorted(c) for c in fit)

# Visualize the network with the identified communities

colors = [
    (
        "plum" if node in communities[0]
        else "yellow" if node in communities[1]
        else "lightblue" if node in communities[2]
        else "orange" 
    )
    for node in Z.nodes
]

# visualize the network
plt.figure(figsize=(6, 4))
nx.draw(
    Z,
    pos = nx.spring_layout(Z, k=0.3),
    with_labels=False,
    node_color=colors,
    node_size=20,
    edge_color=[Z[u][v]["weight"] for u, v in Z.edges],
    edge_cmap=plt.cm.Greens,
    alpha=1, 
    edge_vmin=0,
    edge_vmax=10
)
plt.title("Different Groups within the Genre-Genre Network")
plt.show()

```

# Visualising Genre-Genre Network with Weighted Nodes
```{python}
# Confirms that more central genres have more audience overlap
weighted_degrees = dict(Z.degree(weight="weight"))

plt.figure(figsize=(6, 6))
nx.draw(
    Z,
    pos =nx.spring_layout(Z, k=0.5),
    with_labels=False,
    node_color=colors,
    node_size=[v * 0.01 for v in weighted_degrees.values()],
    edge_color=[Z[u][v]["weight"] for u, v in Z.edges],
    edge_cmap=plt.cm.Greens,
    alpha=0.9,  # Set transparency
    edge_vmin=0,
    edge_vmax=10
)
plt.title("Different Groups within the Genre-Genre Network with Weighted Shared Users")


```

# Creating a Friendship User Network
# AnalyNetwork Measure
```{python}
#Create a user-user graph from edges data using NetworkX to process friendship network
Y = nx.from_pandas_edgelist(fr, source='node_1', target='node_2')

#Calculate network properties
network_metrics = {
    'Number of Users': Y.number_of_nodes(),
    'Number of Connections': Y.number_of_edges(),
    'Network Is Connected': nx.is_connected(Y),
    'Average Clustering Coefficient': nx.average_clustering(Y)
}

print("\nUser Network Summary:")
print(network_metrics)

degree_centrality = nx.degree_centrality(Y)
top_influencers = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]

#Display Top Influencers
print("\nTop 10 Popular Users (by Degree Centrality):")
for user, centrality in top_influencers:
    print(f"User {user}: Centrality = {centrality:.4f}")

```

# Identifying Genres listened to by Most Popular Users

```{python}

pr_json = {int(k): v for k, v in pr_json.items()}

# Count genre frequencies
genre_counter = Counter()

for user, centrality in top_influencers:
    if user not in pr_json:
        print(f"Warning: User {user} not found in pr_json.")
        continue
    user_genres = pr_json[user]
    genre_counter.update(user_genres)

# Display the genre counts
print("\nGenre Counts from Top 10 Popular Users:")
for genre, count in genre_counter.items():
    print(f"{genre}:{count} times")


```

# Creating a unipartite graph to represent user-user network(Y)
# There are too many nodes and edges to project using NetworkX
# Created a adjacency matrix but it doesn't work  

```{python}
import networkx as nx
from scipy.sparse import csr_matrix
from scipy.sparse import vstack

adjacency_matrix = nx.bipartite.biadjacency_matrix(X, row_order=user_nodes)

#adjacency_matrix = csr_matrix(adjacency_matrix)

#chunk_size = 1000  # Number of rows to process at a time
#num_rows = adjacency_matrix.shape[0]

#chunks = []
#for start_row in range(0, num_rows, chunk_size):
    #end_row = min(start_row + chunk_size, num_rows)
    #chunk = adjacency_matrix[start_row:end_row] @ adjacency_matrix.T
    #chunks.append(chunk)

# Combine chunks into a single sparse matrix
#user_user_matrix_sparse = vstack(chunks)
#user_user_matrix_sparse = adjacency_matrix @ adjacency_matrix.T
#print("User-User Matrix Shape (Sparse):", user_user_matrix_sparse.shape)

#if adjacency_matrix.ndim == 1:
#    adjacency_matrix = adjacency_matrix.reshape(1, -1)  
#elif adjacency_matrix.ndim > 2:
#    adjacency_matrix = np.squeeze(adjacency_matrix)

#print(adjacency_matrix.shape)
#print(user_user_matrix_sparse)
```
